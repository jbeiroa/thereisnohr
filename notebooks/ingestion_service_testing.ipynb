{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1192abdb",
   "metadata": {},
   "source": [
    "# Ingestion Service Testing (Stage 3)\n",
    "\n",
    "## Objective\n",
    "Validate `IngestionService` behavior in isolation, without running Metaflow, including deterministic content-based identity resolution and section diagnostics.\n",
    "\n",
    "## Prerequisites\n",
    "1. Run from repository root.\n",
    "2. Have at least one PDF in `data/`.\n",
    "3. Python environment with project dependencies installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e21479-b4c0-4215-8f63-9bc49f9069ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook bootstrap (imports and paths are initialized in the next cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a1c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /Users/juanbeiroa/Code/thereisnohr\n",
      "DATA_DIR: /Users/juanbeiroa/Code/thereisnohr/data\n",
      "Found 5 PDFs\n",
      "[checkpoint] setup complete\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from notebooks._utils import data_dir, list_pdfs, print_checkpoint, project_root\n",
    "from src.ingest.identity import compute_content_hash, extract_identity\n",
    "from src.ingest.service import IngestionService\n",
    "\n",
    "ROOT = project_root()\n",
    "DATA_DIR = data_dir()\n",
    "PDFS = list_pdfs(DATA_DIR)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(f\"Found {len(PDFS)} PDFs\")\n",
    "assert PDFS, \"No PDF files found in data/\"\n",
    "print_checkpoint(\"setup complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7659a46",
   "metadata": {},
   "source": [
    "## 1) Discovery behavior\n",
    "\n",
    "Checks:\n",
    "1. files are discovered recursively\n",
    "2. result is deterministic (sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c63a09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 discovered files:\n",
      "- BeiroaJuanIgnacioCV.pdf\n",
      "- CV_Juan_Beiroa-en.pdf\n",
      "- CV_Juan_Beiroa-es.pdf\n",
      "- JuanBeiroaCV_en_2026.pdf\n",
      "- beiroa_linkedin.pdf\n",
      "[checkpoint] discovery assertions passed\n"
     ]
    }
   ],
   "source": [
    "service = IngestionService()\n",
    "files = service.discover_pdf_files(DATA_DIR)\n",
    "\n",
    "assert files == sorted(files), \"discover_pdf_files must return sorted results\"\n",
    "assert all(p.suffix.lower() == \".pdf\" for p in files), \"discovery should include only PDFs\"\n",
    "\n",
    "print(\"First 5 discovered files:\")\n",
    "for p in files[:5]:\n",
    "    print(\"-\", p.name)\n",
    "print_checkpoint(\"discovery assertions passed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf44b97",
   "metadata": {},
   "source": [
    "## 2) Parser invocation through service\n",
    "\n",
    "Parse a single sample PDF via service boundary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727858c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: BeiroaJuanIgnacioCV.pdf\n",
      "language: es\n",
      "sections: ['general', 'experience']\n",
      "links: ['http://didacTIC.ar', 'https://didactic.ar', 'https://github.com/fifabsas/talleresfifabsas', 'https://github.com/jbeiroa', 'https://github.com/jbeiroa/udciencia']\n",
      "[checkpoint] service parse assertions passed\n"
     ]
    }
   ],
   "source": [
    "sample = files[0]\n",
    "parsed = service.parse_pdf(sample)\n",
    "\n",
    "assert parsed.sections, \"Expected non-empty parsed sections\"\n",
    "assert parsed.parser_version, \"Expected parser version\"\n",
    "\n",
    "print(\"sample:\", sample.name)\n",
    "print(\"language:\", parsed.language)\n",
    "print(\"sections:\", list(parsed.sections.keys()))\n",
    "print(\"links:\", parsed.links[:5])\n",
    "print_checkpoint(\"service parse assertions passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a0e77b-48bb-4ca8-a86a-c0ff2434d397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first section type: general\n",
      "first section confidence: 0.5\n",
      "first section signals: {'diagnostic_flags': ['heading_unknown', 'looks_like_contact_block'], 'confidence_inputs': {'word_count': 27, 'heading_mapped_to_general': True}, 'recategorization_candidate': {'section_type': 'contact', 'confidence': 0.8}}\n",
      "[checkpoint] section diagnostics assertions passed\n"
     ]
    }
   ],
   "source": [
    "assert parsed.section_items, \"Expected non-empty section items\"\n",
    "first_item = parsed.section_items[0]\n",
    "\n",
    "print(\"first section type:\", first_item.normalized_type)\n",
    "print(\"first section confidence:\", first_item.confidence)\n",
    "print(\"first section signals:\", first_item.signals)\n",
    "\n",
    "assert first_item.signals is not None, \"Expected section diagnostics in signals\"\n",
    "assert \"diagnostic_flags\" in first_item.signals\n",
    "assert \"confidence_inputs\" in first_item.signals\n",
    "assert \"recategorization_candidate\" in first_item.signals\n",
    "\n",
    "print_checkpoint(\"section diagnostics assertions passed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa9b8a",
   "metadata": {},
   "source": [
    "## 3) Deterministic content identity checks\n",
    "\n",
    "Validate deterministic identity extraction and content hash behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388cdd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity_key: candidate:v1:fd69152a2fbe992fc27d87e8\n",
      "identity_confidence: 0.973\n",
      "identity_signals keys: ['confidence_inputs', 'emails', 'identity_key_reason', 'model_fallback_used', 'name_signals', 'phones']\n",
      "content_hash: e97a65c62f09dd451ca194afdc75baf2187a95e8dd95a61856ca8e850d6606a0\n",
      "[checkpoint] identity/content-hash assertions passed\n"
     ]
    }
   ],
   "source": [
    "identity_1 = extract_identity(parsed)\n",
    "identity_2 = extract_identity(parsed)\n",
    "\n",
    "assert identity_1.identity_key == identity_2.identity_key, \"identity key must be deterministic\"\n",
    "assert identity_1.confidence >= 0.05\n",
    "assert identity_1.identity_key.startswith((\"candidate:v1:\", \"resume_content:\"))\n",
    "\n",
    "content_hash_1 = compute_content_hash(parsed.clean_text)\n",
    "content_hash_2 = compute_content_hash(parsed.clean_text)\n",
    "assert content_hash_1 == content_hash_2, \"content hash must be deterministic\"\n",
    "assert len(content_hash_1) == 64\n",
    "\n",
    "print(\"identity_key:\", identity_1.identity_key)\n",
    "print(\"identity_confidence:\", identity_1.confidence)\n",
    "print(\"identity_signals keys:\", sorted(identity_1.signals.keys()))\n",
    "print(\"content_hash:\", content_hash_1)\n",
    "print_checkpoint(\"identity/content-hash assertions passed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ba763",
   "metadata": {},
   "source": [
    "## 4) Dry-run ingestion simulation notes\n",
    "\n",
    "This notebook intentionally does not run `ingest_pdf` against DB by default.\n",
    "\n",
    "If you want full persistence checks (identity-key upsert, `content_hash`, section metadata), use `repositories_smoke_testing.ipynb` and/or run Metaflow flow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab11e1",
   "metadata": {},
   "source": [
    "## Summary (fill after run)\n",
    "\n",
    "- Discovery assertions: pass/fail\n",
    "- Parse-through-service assertions: pass/fail\n",
    "- Section diagnostics assertions: pass/fail\n",
    "- Deterministic identity/content-hash assertions: pass/fail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8057cae6",
   "metadata": {},
   "source": [
    "## Next actions\n",
    "\n",
    "1. If identity extraction looks wrong, iterate on heuristics in `src/ingest/identity.py` and lock behavior with `tests/test_identity_resolution.py`.\n",
    "2. If section diagnostics look wrong, refine parser signal builders in `src/ingest/parser.py` and extend `tests/test_ingest_parser.py`.\n",
    "3. If persistence behavior diverges, validate repository wiring in `repositories_smoke_testing.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e89165",
   "metadata": {},
   "source": [
    "## Optional: Inspect Metaflow Run Report + Card\n",
    "\n",
    "After running the flow:\n",
    "\n",
    "```bash\n",
    "uv run python src/ingest/pdf_ingestion_flow.py run --input-dir data --pattern '*.pdf'\n",
    "```\n",
    "\n",
    "You can inspect:\n",
    "1. `run_report` artifact from the flow end step (machine-readable metrics).\n",
    "2. `run_metrics` card for the styled dashboard (status counts, confidence summary, reasons, per-file sample).\n",
    "\n",
    "The report includes: `run_meta`, `status_counts`, `step_timing_summary`, `ingest_quality`, `reason_breakdown`, and `files`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thereisnohr (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
