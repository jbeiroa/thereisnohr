{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfdddc47-ebbb-4852-8ea7-7953d35d0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "import pymupdf\n",
    "import pymupdf4llm\n",
    "from mlx_lm import load, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f4f86b-fb08-47ca-9241-f9db63a3968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2040634e-cb51-4d11-b0a4-27e492baab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to demo files\n",
    "repo_path = os.path.dirname(os.getcwd())\n",
    "cvs_path = os.path.join(repo_path, 'cvs')\n",
    "cvs = [os.path.join(cvs_path, file) for file in os.listdir(cvs_path) if file.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba20b9b-f02a-4909-9f74-afad91f23546",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Getter:\n",
    "    \"\"\"\n",
    "    A class for processing PDF files in a specified directory and converting them to markdown format.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    directory : str\n",
    "        Path to the directory containing PDF files.\n",
    "    save_to_file : bool, optional\n",
    "        If True, saves the converted markdown to a file. Defaults to False.\n",
    "    current_index : int\n",
    "        Tracks the index of the current file being processed. Initialized to 0.\n",
    "    files : List[str]\n",
    "        List of PDF files in the directory. Initialized during object creation.\n",
    "    markdown : Optional[str]\n",
    "        Holds the markdown representation of the last processed file. Defaults to None.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __post_init__():\n",
    "        Initializes the list of PDF files in the directory. Raises FileNotFoundError if no PDF files are found.\n",
    "    \n",
    "    get_cv(path: str) -> str:\n",
    "        Converts a PDF file at the specified path to markdown format.\n",
    "    \n",
    "    get_next() -> Optional[str]:\n",
    "        Processes the next PDF file in the directory and converts it to markdown format.\n",
    "        If `save_to_file` is True, saves the markdown to a file. Returns the markdown or None if no files remain.\n",
    "    \n",
    "    reset():\n",
    "        Resets the processing index to the beginning and clears the last processed markdown.\n",
    "    \"\"\"\n",
    "\n",
    "    directory: str\n",
    "    save_to_file: bool = False\n",
    "    current_index: int = field(init=False, default=0)\n",
    "    files: List[str] = field(init=False)\n",
    "    markdown: Optional[str] = field(init=False, default=None)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the list of PDF files in the directory. Raises a FileNotFoundError\n",
    "        if no PDF files are found in the specified directory.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FileNotFoundError\n",
    "            If no PDF files are found in the specified directory.\n",
    "        \"\"\"\n",
    "        self.files = [file for file in os.listdir(self.directory) if file.endswith('.pdf')]\n",
    "        if not self.files:\n",
    "            raise FileNotFoundError(\"No PDF files found in the specified directory.\")\n",
    "\n",
    "    def get_cv(self, path: str) -> str:\n",
    "        \"\"\"\n",
    "        Converts a PDF file at the specified path to markdown format.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Path to the PDF file to be converted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The markdown representation of the PDF file.\n",
    "        \"\"\"\n",
    "        self.markdown = pymupdf4llm.to_markdown(path, show_progress=False)\n",
    "        return self.markdown\n",
    "    \n",
    "    def get_next(self) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Processes the next PDF file in the directory and converts it to markdown format.\n",
    "        If `save_to_file` is True, saves the markdown to a file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Optional[str]\n",
    "            The markdown representation of the next PDF file, or None if no files remain.\n",
    "        \"\"\"\n",
    "        if self.current_index >= len(self.files):\n",
    "            return None\n",
    "        \n",
    "        current_file_path = os.path.join(self.directory, self.files[self.current_index])\n",
    "        self.current_index += 1\n",
    "        \n",
    "        self.markdown = self.get_cv(current_file_path)\n",
    "        \n",
    "        if self.save_to_file:\n",
    "            md_file_path = os.path.splitext(current_file_path)[0] + \".md\"\n",
    "            with open(md_file_path, 'w', encoding='utf-8') as md_file:\n",
    "                md_file.write(self.markdown)\n",
    "        \n",
    "        return self.markdown\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the processing index to the beginning and clears the last processed markdown.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.current_index = 0\n",
    "        self.markdown = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba13e24a-b2a8-46da-bc70-b5496dd3f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ResumeCleaner:\n",
    "    \"\"\"\n",
    "    Cleans a Markdown-formatted resume into a flat, readable plain text format\n",
    "    resembling the structure of the training data.\n",
    "    \"\"\"\n",
    "\n",
    "    def clean(self, text) -> str:\n",
    "\n",
    "        # 1. Remove markdown headings (e.g., #, ##, ###)\n",
    "        text = re.sub(r\"^#+\\s*\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "        # 2. Remove markdown links: [text](url) â†’ text\n",
    "        text = re.sub(r\"\\[([^\\]]+)\\]\\([^\\)]+\\)\", r\"\\1\", text)\n",
    "\n",
    "        # 3. Remove standalone markdown list markers (*, -, +)\n",
    "        text = re.sub(r\"^[\\*\\-\\+]\\s*\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "        # 4. Collapse multiple newlines into one\n",
    "        text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "\n",
    "        # 5. Fix email and phone numbers with weird formats\n",
    "        text = re.sub(r\"\\s?[\\[\\(]mailto:([^\\)\\]]+)[\\)\\]]\", r\"\\1\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text)  # Normalize whitespace\n",
    "\n",
    "        # 6. Remove repeated name sections (e.g., \"# John Doe\" twice)\n",
    "        lines = text.splitlines()\n",
    "        seen_lines = set()\n",
    "        cleaned_lines = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line and line not in seen_lines:\n",
    "                seen_lines.add(line)\n",
    "                cleaned_lines.append(line)\n",
    "        text = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "        # 7. Optional: standardize contact labels\n",
    "        text = re.sub(r\"\\b([Pp]hone)\\b[:\\-]?\", \"Phone:\", text)\n",
    "        text = re.sub(r\"\\b([Ee]mail)\\b[:\\-]?\", \"Email:\", text)\n",
    "        text = re.sub(r\"\\b([Ll]inkedIn)\\b[:\\-]?\", \"LinkedIn:\", text)\n",
    "\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bf6f373-8301-4311-a329-de18c7ed134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Profiler:\n",
    "    \"\"\"\n",
    "    A class for summarizing rÃ©sumÃ©s using a preloaded MLX model from Hugging Face.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : str\n",
    "        Hugging Face model ID (MLX-compatible).\n",
    "    save_to_file : bool\n",
    "        Whether to save each generated summary to file (optional).\n",
    "    \"\"\"\n",
    "\n",
    "    model: str = 'jbeiroa/Llama-3.2-1B-It-mlx-ft'\n",
    "    save_to_file: bool = False\n",
    "\n",
    "    _model_instance: Optional[any] = field(init=False, default=None)\n",
    "    _tokenizer: Optional[any] = field(init=False, default=None)\n",
    "\n",
    "    _chunk_size: int = 1500\n",
    "    _overlap: int = 250\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads the MLX model and tokenizer from Hugging Face.\n",
    "        Only needs to be called once.\n",
    "        \"\"\"\n",
    "        print(f\"ðŸ”„ Loading model from {self.model}...\")\n",
    "        self._model_instance, self._tokenizer = load(self.model)\n",
    "        print(f\"âœ… Model loaded.\")\n",
    "\n",
    "    def unload_model(self):\n",
    "        \"\"\"\n",
    "        Releases the MLX model and tokenizer from memory.\n",
    "        \"\"\"\n",
    "        print(\"ðŸ§¹ Unloading model and tokenizer from memory...\")\n",
    "        del self._model_instance\n",
    "        del self._tokenizer\n",
    "        self._model_instance = None\n",
    "        self._tokenizer = None\n",
    "        gc.collect()\n",
    "        print(\"âœ… Model unloaded.\")\n",
    "\n",
    "    def _split_resume_into_chunks(self, resume: str) -> List[str]:\n",
    "        tokens = self._tokenizer.encode(resume)\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        while start < len(tokens):\n",
    "            end = start + self._chunk_size\n",
    "            chunk = tokens[start:end]\n",
    "            text = self._tokenizer.decode(chunk)\n",
    "            chunks.append(text)\n",
    "            start += self._chunk_size - self._overlap\n",
    "        return chunks\n",
    "\n",
    "    def summarize(self, resume: str, skip_chunking_if_short: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Summarizes a given resume using the loaded MLX model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        resume : str\n",
    "            The resume text to summarize.\n",
    "        skip_chunking_if_short : bool\n",
    "            If True, skips chunking if the resume is under 2048 tokens.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The summary of the resume.\n",
    "        \"\"\"\n",
    "        if self._model_instance is None or self._tokenizer is None:\n",
    "            raise RuntimeError(\"Model not loaded. Call `load_model()` first.\")\n",
    "\n",
    "        tokens = self._tokenizer.encode(resume)\n",
    "\n",
    "        if skip_chunking_if_short and len(tokens) <= 2048:\n",
    "            prompt = (\n",
    "                \"Summarize the following resume in 3-4 sentences, focusing on key skills, experience, and education.\\n\\n\"\n",
    "                f\"{resume}\"\n",
    "            )\n",
    "            response = generate(\n",
    "                self._model_instance,\n",
    "                self._tokenizer,\n",
    "                prompt,\n",
    "                verbose=False\n",
    "            )\n",
    "            summary = response.strip()\n",
    "        else:\n",
    "            chunks = self._split_resume_into_chunks(resume)\n",
    "            summary = ''\n",
    "            for chunk in chunks:\n",
    "                prompt = (\n",
    "                    \"Summarize the following resume in 3-4 sentences, focusing on key skills, experience, and education.\\n\\n\"\n",
    "                    f\"{chunk}\"\n",
    "                )\n",
    "                response = generate(\n",
    "                    self._model_instance,\n",
    "                    self._tokenizer,\n",
    "                    prompt,\n",
    "                    verbose=False\n",
    "                )\n",
    "                summary += response.strip() + \"\\n\\n\"\n",
    "\n",
    "        if self.save_to_file:\n",
    "            with open(\"resume_summary.txt\", \"w\") as f:\n",
    "                f.write(summary.strip())\n",
    "\n",
    "        return summary.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa87471-bf87-47bd-85b0-dc6028a749ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = Getter(cvs_path)\n",
    "cleaner = ResumeCleaner()\n",
    "cvs = []\n",
    "\n",
    "while True:\n",
    "    cv = getter.get_next()\n",
    "    if cv is None:\n",
    "        break\n",
    "    cleaned_text = cleaner.clean(cv)\n",
    "    cvs.append(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c8bbaf5-f58b-45cb-bbb9-3cb36713e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "/var/folders/37/p_kmm_0n64s1b89v_jyrfxq40000gn/T/ipykernel_2168/1542397985.py:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  test_resume = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "test_resume = \"\"\"\n",
    "Hunter Castillo Contact Information: * Email: [hunter.castillo@email.com](mailto:hunter.castillo@email.com) * Phone: (555) 123-4567 * LinkedIn: linkedin.com\\/in\\/huntercastillo * GitHub: github.com\\/huntercastillo Professional Summary: Highly motivated and experienced Cloud Engineer with a strong background in Serverless Architecture, Cloud Networking, and Scripting. Proven track record of designing and deploying scalable, secure, and efficient cloud infrastructure solutions. Skilled in automating repetitive tasks through scripting and passionate about staying up-to-date with the latest cloud technologies. Technical Skills: * Cloud Platforms: AWS, Azure, Google Cloud * Serverless Architecture: AWS Lambda, Azure Functions, Google Cloud Functions * Cloud Networking: AWS VPC, Azure Virtual Network, Google Cloud Network * Scripting: Python, Bash, PowerShell * Cloud Security: IAM, Access Control, Encryption * DevOps Tools: Terraform, Ansible, Docker * Agile Methodologies: Scrum, Kanban Professional Experience: Cloud Engineer, ABC Corporation (2020-Present) * Designed and deployed scalable cloud infrastructure solutions for multiple clients using Serverless Architecture and Cloud Networking * Implemented automation scripts using Python and Bash to streamline deployment and management processes * Collaborated with cross-functional teams to ensure seamless integration with existing infrastructure and applications * Developed and maintained cloud security policies and procedures to ensure compliance with industry standards * Participated in code reviews and contributed to the development of reusable code modules Senior Cloud Consultant, DEF Consulting (2018-2020) * Provided cloud architecture and migration services to clients across various industries * Conducted technical assessments and developed recommendations for cloud infrastructure optimization * Designed and implemented cloud-based solutions for data analytics and machine learning workloads * Trained and mentored junior team members on cloud technologies and best practices * Developed and delivered technical presentations and workshops on cloud-related topics Education: * Bachelor's Degree in Computer Science, XYZ University (2015-2019) Certifications: * AWS Certified Solutions Architect - Professional * Azure Certified Azure Developer Associate * Google Cloud Certified - Professional Cloud Developer Achievements: * Developed and deployed a Serverless Architecture solution for a large e-commerce client, resulting in a 30% reduction in infrastructure costs * Designed and implemented a cloud-based security solution for a financial services client, achieving a 99.99% uptime and 0 security breaches * Collaborated with a team to develop and deploy a cloud-based data analytics platform, achieving a 50% increase in data processing speeds References: Available upon request. I hope this sample resume helps! Remember to tailor your own resume to your specific experiences and qualifications, and don't hesitate to reach out if you have any questions or need further assistance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96ee1269-8313-4d9a-a1a8-78f9027db6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading model from jbeiroa/Llama-3.2-1B-It-mlx-ft...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475195e99d6f43e49a63aebf31f0d7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded.\n",
      "Note: The sample resume is just a starting point, and you should customize it to fit your own experiences and qualifications. Also, be sure to proofread your resume multiple times for any grammar or formatting errors. Good luck!\n",
      "ðŸ§¹ Unloading model and tokenizer from memory...\n",
      "âœ… Model unloaded.\n"
     ]
    }
   ],
   "source": [
    "profiler = Profiler(model='jbeiroa/Llama-3.2-1B-It-mlx-ft')\n",
    "profiler.load_model()\n",
    "summary = profiler.summarize(test_resume)\n",
    "print(summary)\n",
    "profiler.unload_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbd3fa-4b54-4885-b5e9-7b17f82edd86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
