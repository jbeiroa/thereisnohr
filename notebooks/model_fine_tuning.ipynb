{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75df61f4-4911-4cc8-ab88-088d69b846cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from mlx_lm import load, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8508871-7e5e-414d-9757-091ab0cc0e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb5751c5de84e6ea310daa4dbd6882b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c6471-a399-425a-b46b-0e5201912466",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b24d3a-8a50-48ab-aa36-38d12c9d4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"jbeiroa/resume-summarization-dataset\")\n",
    "train = dataset[\"train\"]\n",
    "val = dataset[\"validation\"]\n",
    "test = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0a47e29-c53f-4f79-977f-cf1bcdb5d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1500\n",
    "OVERLAP = 250\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "def split_resume_into_chunks(resume_text, chunk_size=CHUNK_SIZE, overlap=OVERLAP):\n",
    "    tokens = tokenizer.encode(resume_text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + chunk_size\n",
    "        chunk = tokens[start:end]\n",
    "        text = tokenizer.decode(chunk)\n",
    "        chunks.append(text)\n",
    "        start += chunk_size - overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd10f3a5-db06-477b-8392-9c21f63b5330",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = (\n",
    "    \"Summarize the following resume in 3-4 sentences, focusing on key skills, experience, and education.\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8448064-c513-411b-9477-484061c84fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_split(split):\n",
    "    training_pairs = []\n",
    "    for example in split:\n",
    "        chunks = split_resume_into_chunks(example[\"resume\"])\n",
    "        for chunk in chunks:\n",
    "            training_pairs.append({\n",
    "                \"prompt\": PROMPT_TEMPLATE + chunk,\n",
    "                \"response\": example[\"summary\"]\n",
    "            })\n",
    "    return training_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7504a656-0141-4994-ab31-c2f3a14b3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mlx = convert_split(train)\n",
    "val_mlx = convert_split(val)\n",
    "test_mlx = convert_split(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2266483-f902-4493-9e3f-f71782ac6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_jsonl(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "save_jsonl(train_mlx, \"/Users/juanbeiroa/Code/thereisnohr/data/finetuning/train.jsonl\")\n",
    "save_jsonl(val_mlx, \"/Users/juanbeiroa/Code/thereisnohr/data/finetuning/valid.jsonl\")\n",
    "save_jsonl(test_mlx, \"/Users/juanbeiroa/Code/thereisnohr/data/finetuning/test.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e47f4b-4790-4747-842c-039c309e0f20",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f9ebed6-33ce-4248-a059-b6b31cbc8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_finetune = {\n",
    "    \"phi2\": \"microsoft/phi-2\",\n",
    "    \"tinyllama\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    \"gemma2b\": \"mlx-community/gemma-2-2b-it\",\n",
    "    \"llama3.2\": \"mlx-community/Llama-3.2-1B-Instruct-MLXTuned\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663457f4-f46f-4712-930c-f49cf8d073a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlx_lm.lora \\\n",
    "    --model TinyLlama/TinyLlama-1.1B-Chat-v1.0 \\\n",
    "    --train \\\n",
    "    --data ~/Code/thereisnohr/data/finetuning \\\n",
    "    --adapter-path ~/Code/thereisnohr/adapters/tinyllama \\\n",
    "    --batch-size 2 \\\n",
    "    --num-layers 4 \\\n",
    "    --grad-checkpoint \\\n",
    "    --test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
