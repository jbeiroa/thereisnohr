{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75df61f4-4911-4cc8-ab88-088d69b846cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from mlx_lm import load, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8508871-7e5e-414d-9757-091ab0cc0e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72465f6603d4cb3a0588bce01b004d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c6471-a399-425a-b46b-0e5201912466",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b24d3a-8a50-48ab-aa36-38d12c9d4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"jbeiroa/resume-summarization-dataset\")\n",
    "train = dataset[\"train\"]\n",
    "val = dataset[\"validation\"]\n",
    "test = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a47e29-c53f-4f79-977f-cf1bcdb5d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2245 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting of train data for microsoft/phi-2 finished.\n",
      "Splitting of validation data for microsoft/phi-2 finished.\n",
      "Splitting of test data for microsoft/phi-2 finished.\n",
      "Saved train.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/phi-finetuning/\n",
      "Saved valid.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/phi-finetuning/\n",
      "Saved test.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/phi-finetuning/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3367891404a3454abc9b3ed377e7187d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14aa908a0524ac494cefdd708b38fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c120d5373904df1b5492de8d70d01ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f0cdb277aa483487630c572c88e5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2800 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting of train data for mlx-community/TinyLlama-1.1B-Chat-v1.0-mlx finished.\n",
      "Splitting of validation data for mlx-community/TinyLlama-1.1B-Chat-v1.0-mlx finished.\n",
      "Splitting of test data for mlx-community/TinyLlama-1.1B-Chat-v1.0-mlx finished.\n",
      "Saved train.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/tinyllama-finetuning/\n",
      "Saved valid.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/tinyllama-finetuning/\n",
      "Saved test.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/tinyllama-finetuning/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fb5182293e4e6dab6944b270e703c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/46.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421f57ab276e497a87b26d04af2d97a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f300ebee816048c5b1c589045710304a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e5eefc8ec74679aff5cdc6cb6b8ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/555 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting of train data for mlx-community/gemma-2-2b-it finished.\n",
      "Splitting of validation data for mlx-community/gemma-2-2b-it finished.\n",
      "Splitting of test data for mlx-community/gemma-2-2b-it finished.\n",
      "Saved train.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/gemma-finetuning/\n",
      "Saved valid.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/gemma-finetuning/\n",
      "Saved test.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/gemma-finetuning/\n",
      "Splitting of train data for mlx-community/Llama-3.2-1B-Instruct-MLXTuned finished.\n",
      "Splitting of validation data for mlx-community/Llama-3.2-1B-Instruct-MLXTuned finished.\n",
      "Splitting of test data for mlx-community/Llama-3.2-1B-Instruct-MLXTuned finished.\n",
      "Saved train.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/llama-finetuning/\n",
      "Saved valid.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/llama-finetuning/\n",
      "Saved test.jsonl to /Users/juanbeiroa/Code/thereisnohr/data/llama-finetuning/\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 1500\n",
    "OVERLAP = 250\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"Summarize the following resume in 3-4 sentences, focusing on key skills, experience, and education.\\n\\n\"\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "\n",
    "models_to_finetune = [\n",
    "    \"microsoft/phi-2\",\n",
    "    \"mlx-community/TinyLlama-1.1B-Chat-v1.0-mlx\",\n",
    "    \"mlx-community/gemma-2-2b-it\",\n",
    "    \"mlx-community/Llama-3.2-1B-Instruct-MLXTuned\"\n",
    "]\n",
    "\n",
    "out_dirs = [\n",
    "    \"/Users/juanbeiroa/Code/thereisnohr/data/phi-finetuning/\",\n",
    "    \"/Users/juanbeiroa/Code/thereisnohr/data/tinyllama-finetuning/\",\n",
    "    \"/Users/juanbeiroa/Code/thereisnohr/data/gemma-finetuning/\",\n",
    "    \"/Users/juanbeiroa/Code/thereisnohr/data/llama-finetuning/\"\n",
    "]\n",
    "\n",
    "def split_resume_into_chunks(resume_text, tokenizer, chunk_size=CHUNK_SIZE, overlap=OVERLAP):\n",
    "    tokens = tokenizer.encode(resume_text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + chunk_size\n",
    "        chunk = tokens[start:end]\n",
    "        text = tokenizer.decode(chunk)\n",
    "        chunks.append(text)\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def convert_split(split, tokenizer):\n",
    "    training_pairs = []\n",
    "    for example in split:\n",
    "        chunks = split_resume_into_chunks(example[\"resume\"], tokenizer)\n",
    "        for chunk in chunks:\n",
    "            training_pairs.append({\n",
    "                \"prompt\": PROMPT_TEMPLATE + chunk,\n",
    "                \"completion\": example[\"summary\"]\n",
    "            })\n",
    "    return training_pairs\n",
    "\n",
    "def save_jsonl(data, filename):\n",
    "    with open(filename, \"w+\") as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "for model, path in zip(models_to_finetune, out_dirs):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    train_mlx = convert_split(train, tokenizer)\n",
    "    print(f\"Splitting of train data for {model} finished.\")\n",
    "    val_mlx = convert_split(val, tokenizer)\n",
    "    print(f\"Splitting of validation data for {model} finished.\")\n",
    "    test_mlx = convert_split(test, tokenizer)\n",
    "    print(f\"Splitting of test data for {model} finished.\")\n",
    "    save_jsonl(train_mlx, path + \"train.jsonl\")\n",
    "    print(f\"Saved train.jsonl to {path}\")\n",
    "    save_jsonl(val_mlx, path + \"valid.jsonl\")\n",
    "    print(f\"Saved valid.jsonl to {path}\")\n",
    "    save_jsonl(test_mlx, path + \"test.jsonl\")\n",
    "    print(f\"Saved test.jsonl to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e47f4b-4790-4747-842c-039c309e0f20",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663457f4-f46f-4712-930c-f49cf8d073a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlx_lm.lora \\\n",
    "    --model mlx-community/Llama-3.2-1B-Instruct-MLXTuned \\\n",
    "    --train \\\n",
    "    --data ~/Code/thereisnohr/data/llama-finetuning \\\n",
    "    --adapter-path ~/Code/thereisnohr/adapters/llama-3.2-1b \\\n",
    "    --batch-size 2 \\\n",
    "    --num-layers 4 \\\n",
    "    --test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae410d-7024-4bcb-8c0c-5e9ddb8b25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlx_lm.lora \\\n",
    "    --model mlx-community/gemma-2-2b-it \\\n",
    "    --train \\\n",
    "    --data ~/Code/thereisnohr/data/gemma-finetuning \\\n",
    "    --adapter-path ~/Code/thereisnohr/adapters/gemma \\\n",
    "    --batch-size 2 \\\n",
    "    --num-layers 4 \\\n",
    "    --grad-checkpoint \\\n",
    "    --test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae30c4-9e29-4392-ae0f-45acf6e80a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlx_lm.lora \\\n",
    "    --model microsoft/phi-2 \\\n",
    "    --train \\\n",
    "    --data ~/Code/thereisnohr/data/phi-finetuning \\\n",
    "    --adapter-path ~/Code/thereisnohr/adapters/phi-2 \\\n",
    "    --batch-size 2 \\\n",
    "    --num-layers 4 \\\n",
    "    --grad-checkpoint \\\n",
    "    --test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845165a-7b8e-4866-b32f-5cc04440b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlx_lm.lora \\\n",
    "    --model mlx-community/TinyLlama-1.1B-Chat-v1.0-mlx \\\n",
    "    --train \\\n",
    "    --data ~/Code/thereisnohr/data/tinyllama-finetuning \\\n",
    "    --adapter-path ~/Code/thereisnohr/adapters/tinyllama \\\n",
    "    --batch-size 2 \\\n",
    "    --num-layers 4 \\\n",
    "    --test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
