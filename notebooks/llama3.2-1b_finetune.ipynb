{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75df61f4-4911-4cc8-ab88-088d69b846cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from mlx_lm import load, generate, convert, lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8508871-7e5e-414d-9757-091ab0cc0e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf7ac0100a342ee9718a461aaabcb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f22674-4138-4c39-95e7-0d68212352ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'meta-llama/Llama-3.2-1B'\n",
    "#convert(model_path, q_bits=8, upload_repo='jbeiroa/mlx_llama-3.2-1b-q8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f51737-99e2-4caa-bacc-2aa4ac3c38c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eddf3bb397e4e8b8c51af77130e5b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load('jbeiroa/mlx_llama-3.2-1b-q8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee9f35b-32de-4ae3-a31a-5760b5dcaea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: Who was Albert Einstein?\n",
      "Einstein was a German-born theoretical physicist who developed the general theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics). He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\". He is best known for his mass–energy equivalence formula E = mc2 (which has been dubbed \"the world's most famous equation\"), first proposed in 1905. His work is also known for its influence on the philosophy of science. He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\". He is best known for his mass–energy equivalence formula E = mc2 (which has been dubbed \"the world's most famous equation\"), first proposed in 1905. His work is also known for its influence on the philosophy of science.\n",
      "==========\n",
      "Prompt: 6 tokens, 131.561 tokens-per-sec\n",
      "Generation: 193 tokens, 35.456 tokens-per-sec\n",
      "Peak memory: 2.549 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Einstein was a German-born theoretical physicist who developed the general theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics). He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\". He is best known for his mass–energy equivalence formula E = mc2 (which has been dubbed \"the world\\'s most famous equation\"), first proposed in 1905. His work is also known for its influence on the philosophy of science. He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\". He is best known for his mass–energy equivalence formula E = mc2 (which has been dubbed \"the world\\'s most famous equation\"), first proposed in 1905. His work is also known for its influence on the philosophy of science.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, tokenizer,\n",
    "              prompt='Who was Albert Einstein?', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea4f873e-ed3d-4405-9d07-bc2316c41f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('jbeiroa/resume_entities_ner_summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac8a2435-29d2-4161-85b9-f3ff02ba33bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'annotation', 'highlight', 'length', 'summary'],\n",
       "        num_rows: 154\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['content', 'annotation', 'highlight', 'length', 'summary'],\n",
       "        num_rows: 66\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c58664f9-adac-44d8-8578-a17dd4dd605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train'].to_pandas()\n",
    "_ = dataset['test'].to_pandas()\n",
    "test = _.sample(frac=0.5)\n",
    "msk = test.index\n",
    "valid = _.loc[~_.index.isin(msk)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8477370e-6922-4a84-967a-96cc3921673b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "      <th>highlight</th>\n",
       "      <th>length</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Ayushi Srivastava\\nSenior Analyst - Cisco\\n\\nN...</td>\n",
       "      <td>[{'label': ['Email Address'], 'points': [{'end...</td>\n",
       "      <td>{'College Name': 'Sumermal Jain Public School\n",
       "...</td>\n",
       "      <td>2110</td>\n",
       "      <td>*Name*: Ayushi Srivastava.\\n*Skills*: CSS (Les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Harini Komaravelli\\nTest Analyst at Oracle, Hy...</td>\n",
       "      <td>[{'label': ['Companies worked at'], 'points': ...</td>\n",
       "      <td>{'College Name': 'Osmania University\n",
       "Osmania U...</td>\n",
       "      <td>5203</td>\n",
       "      <td>*Name*: Harini Komaravelli.\\n*Skills*: Functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Avin Sharma\\nSenior Associate Consultant - Inf...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'end': 2478...</td>\n",
       "      <td>{'College Name': 'Great Lakes Institute of Man...</td>\n",
       "      <td>2479</td>\n",
       "      <td>*Name*: Avin Sharma.\\n*Skills*: Bid management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Vikas Singh\\nChandigarh, Chandigarh - Email me...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'end': 5749...</td>\n",
       "      <td>{'College Name': 'GLA Institute of Technology ...</td>\n",
       "      <td>5750</td>\n",
       "      <td>*Name*: Vikas Singh.\\n*Skills*: SECURITY (5 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roshan Sinha\\nApplication Developer - SAP ABAP...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'end': 3263...</td>\n",
       "      <td>{'College Name': 'Anna University Chennai', 'C...</td>\n",
       "      <td>3264</td>\n",
       "      <td>*Name*: Roshan Sinha.\\n*Skills*: OOPS-ABAP\\nSA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  \\\n",
       "117  Ayushi Srivastava\\nSenior Analyst - Cisco\\n\\nN...   \n",
       "45   Harini Komaravelli\\nTest Analyst at Oracle, Hy...   \n",
       "153  Avin Sharma\\nSenior Associate Consultant - Inf...   \n",
       "92   Vikas Singh\\nChandigarh, Chandigarh - Email me...   \n",
       "3    Roshan Sinha\\nApplication Developer - SAP ABAP...   \n",
       "\n",
       "                                            annotation  \\\n",
       "117  [{'label': ['Email Address'], 'points': [{'end...   \n",
       "45   [{'label': ['Companies worked at'], 'points': ...   \n",
       "153  [{'label': ['Skills'], 'points': [{'end': 2478...   \n",
       "92   [{'label': ['Skills'], 'points': [{'end': 5749...   \n",
       "3    [{'label': ['Skills'], 'points': [{'end': 3263...   \n",
       "\n",
       "                                             highlight  length  \\\n",
       "117  {'College Name': 'Sumermal Jain Public School\n",
       "...    2110   \n",
       "45   {'College Name': 'Osmania University\n",
       "Osmania U...    5203   \n",
       "153  {'College Name': 'Great Lakes Institute of Man...    2479   \n",
       "92   {'College Name': 'GLA Institute of Technology ...    5750   \n",
       "3    {'College Name': 'Anna University Chennai', 'C...    3264   \n",
       "\n",
       "                                               summary  \n",
       "117  *Name*: Ayushi Srivastava.\\n*Skills*: CSS (Les...  \n",
       "45   *Name*: Harini Komaravelli.\\n*Skills*: Functio...  \n",
       "153  *Name*: Avin Sharma.\\n*Skills*: Bid management...  \n",
       "92   *Name*: Vikas Singh.\\n*Skills*: SECURITY (5 ye...  \n",
       "3    *Name*: Roshan Sinha.\\n*Skills*: OOPS-ABAP\\nSA...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7d2be0-17b9-43ff-9e1d-52e023a6facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([27,  5, 22, 29, 16,  2,  1, 39,  4, 37, 26, 47, 30, 20, 59, 36, 43, 56,\n",
       "       61, 17,  3, 10, 31, 12, 25, 45, 60, 55, 64, 44, 41, 42, 14],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79f3b95-1b58-4873-8bcf-e9f6176fc47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 0,  6,  7,  8,  9, 11, 13, 15, 18, 19, 21, 23, 24, 28, 32, 33, 34, 35,\n",
       "       38, 40, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 62, 63, 65],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1b01b77-6b0e-452a-945d-c96de7c3cfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*Name*: Mohini Gupta.\\n*Skills*: active directory, iis, sccm, dhcp, sql, wsus, dns\\n\\nADDITIONAL INFORMATION\\n\\nComputer Skills\\n● MS Office Tools: MS Excel, MS Word, MS Power Point.\\n● Hands on experience on all versions of Windows.\\n● Sound knowledge of internet and networking.\\n● Coding Languages: C, C++, Java..\\n*College Name*: KIIT college of Engg..\\n*Degree*: B.tech.\\n*Companies worked at*: Microsoft\\nMicrosoft.\\n*Designation*: Server Support Engineer\\nServer Support Engineer.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abec90e3-5950-4794-bac2-94e5433d6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_instruction = lambda content, summary: f\"\"\"<|begin_of_text|><|start_header_id|>system><|end_header_id|>\n",
    "You are a helpful human resources assistant, specialized in resume analysis and data extraction from job candidate applicants. \n",
    "When asked to summarize a resume, you should structure your output in this format format:\n",
    "*Name*: [Candidate name]\n",
    "*Skills*: [Candidate skills]\n",
    "*Degree*: [Candidate degrees]\n",
    "*Companies worked at*: [Candidate job experience]\n",
    "*Designation*: [Candidate job roles]<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Task: summarize the following resume using the specified structure:   \n",
    "{content}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{summary}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c1add80-3536-4bfd-bba1-c124d209aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train.apply(lambda x: build_instruction(x.content, x.summary), axis=1)\n",
    "test['text'] = test.apply(lambda x: build_instruction(x.content, x.summary), axis=1)\n",
    "valid['text'] = valid.apply(lambda x: build_instruction(x.content, x.summary), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "542f8d8f-1ad6-4728-813e-4a3c366e1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokenized'] = train.apply(lambda x: tokenizer.encode(x.text), axis=1)\n",
    "test['tokenized'] = train.apply(lambda x: tokenizer.encode(x.text), axis=1)\n",
    "valid['tokenized'] = train.apply(lambda x: tokenizer.encode(x.text), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23bfe0ec-3c2d-485e-8ff1-0f41e0b2d394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154, 7), (33, 7), (33, 7))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80d290f5-6f2b-4eeb-8607-1ffcf04e2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.tokenized.map(len) <= 2048]\n",
    "test = test[test.tokenized.map(len) <= 2048]\n",
    "valid = valid[valid.tokenized.map(len) <= 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cba7ce6f-d180-43c5-86d0-eae2c203b1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142, 7), (31, 7), (31, 7))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43e998dc-d025-490d-a963-4e1021be7dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to save the JSONL file\n",
    "output_file = \"train.jsonl\"\n",
    "\n",
    "# Writing to JSONL\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for _, row in train.iterrows():  # Iterate over each row\n",
    "        json_line = {'text': row['text']}  # Wrap each text in a dictionary\n",
    "        f.write(json.dumps(json_line) + '\\n')  # Convert dict to JSON string and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10b499fc-0813-4d14-813c-7f300c0489b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save the JSONL file\n",
    "output_file = \"test.jsonl\"\n",
    "\n",
    "# Writing to JSONL\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for _, row in test.iterrows():  # Iterate over each row\n",
    "        json_line = {'text': row['text']}  # Wrap each text in a dictionary\n",
    "        f.write(json.dumps(json_line) + '\\n')  # Convert dict to JSON string and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37714828-4d17-46ab-8eb0-10a5a735bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save the JSONL file\n",
    "output_file = \"valid.jsonl\"\n",
    "\n",
    "# Writing to JSONL\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for _, row in valid.iterrows():  # Iterate over each row\n",
    "        json_line = {'text': row['text']}  # Wrap each text in a dictionary\n",
    "        f.write(json.dumps(json_line) + '\\n')  # Convert dict to JSON string and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67930129-e9d7-484a-a5e3-d468376db06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\n",
      "Fetching 6 files: 100%|████████████████████████| 6/6 [00:00<00:00, 19166.66it/s]\n",
      "Loading datasets\n",
      "Training\n",
      "Trainable parameters: 0.069% (0.852M/1235.814M)\n",
      "Starting training..., iters: 600\n",
      "Iter 1: Val loss 2.718, Val took 31.294s\n",
      "Iter 60: Val loss 2.647, Val took 39.763s\n",
      "Iter 60: Train loss 2.913, Learning Rate 1.000e-06, It/sec 16.515, Tokens/sec 30842.330, Trained Tokens 112051, Peak mem 14.342 GB\n",
      "Iter 100: Saved adapter weights to adapters/adapters.safetensors and adapters/0000100_adapters.safetensors.\n",
      "Iter 120: Val loss 2.595, Val took 40.880s\n",
      "Iter 120: Train loss 2.794, Learning Rate 1.000e-06, It/sec 10.257, Tokens/sec 19115.667, Trained Tokens 223866, Peak mem 14.398 GB\n",
      "Iter 180: Val loss 2.553, Val took 45.680s\n",
      "Iter 180: Train loss 2.741, Learning Rate 1.000e-06, It/sec 3.915, Tokens/sec 7389.507, Trained Tokens 337121, Peak mem 14.398 GB\n",
      "Iter 200: Saved adapter weights to adapters/adapters.safetensors and adapters/0000200_adapters.safetensors.\n",
      "Iter 240: Val loss 2.517, Val took 37.645s\n",
      "Iter 240: Train loss 2.700, Learning Rate 1.000e-06, It/sec 6.836, Tokens/sec 13222.191, Trained Tokens 453176, Peak mem 14.399 GB\n",
      "Iter 300: Val loss 2.485, Val took 40.588s\n",
      "Iter 300: Train loss 2.652, Learning Rate 1.000e-06, It/sec 12.893, Tokens/sec 25361.904, Trained Tokens 571203, Peak mem 14.399 GB\n",
      "Iter 300: Saved adapter weights to adapters/adapters.safetensors and adapters/0000300_adapters.safetensors.\n",
      "Iter 360: Val loss 2.455, Val took 41.421s\n",
      "Iter 360: Train loss 2.598, Learning Rate 1.000e-06, It/sec 14.130, Tokens/sec 25324.546, Trained Tokens 678738, Peak mem 14.399 GB\n",
      "Iter 400: Saved adapter weights to adapters/adapters.safetensors and adapters/0000400_adapters.safetensors.\n",
      "Iter 420: Val loss 2.427, Val took 41.992s\n",
      "Iter 420: Train loss 2.573, Learning Rate 1.000e-06, It/sec 16.936, Tokens/sec 32764.188, Trained Tokens 794813, Peak mem 14.399 GB\n",
      "Iter 480: Val loss 2.400, Val took 42.685s\n",
      "Iter 480: Train loss 2.528, Learning Rate 1.000e-06, It/sec 5.982, Tokens/sec 11187.129, Trained Tokens 907026, Peak mem 14.399 GB\n",
      "Iter 500: Saved adapter weights to adapters/adapters.safetensors and adapters/0000500_adapters.safetensors.\n",
      "Iter 540: Val loss 2.375, Val took 41.915s\n",
      "Iter 540: Train loss 2.498, Learning Rate 1.000e-06, It/sec 6.568, Tokens/sec 12776.864, Trained Tokens 1023754, Peak mem 14.399 GB\n",
      "Iter 600: Val loss 2.348, Val took 41.989s\n",
      "Iter 600: Train loss 2.462, Learning Rate 1.000e-06, It/sec 3.943, Tokens/sec 7332.351, Trained Tokens 1135339, Peak mem 14.399 GB\n",
      "Iter 600: Saved adapter weights to adapters/adapters.safetensors and adapters/0000600_adapters.safetensors.\n",
      "Saved final weights to adapters/adapters.safetensors.\n",
      "Testing\n",
      "Test loss 2.350, Test ppl 10.486.\n"
     ]
    }
   ],
   "source": [
    "!mlx_lm.lora --model jbeiroa/mlx_llama-3.2-1b-q8 --train --fine-tune-type lora --num-layers 16 --iters 600 --learning-rate 1e-6 --batch-size 2 --steps-per-report 60 --steps-per-eval 60 --test --grad-checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1172a5a-92d3-47e3-966c-95ffbf2e7f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\n",
      "Fetching 6 files: 100%|████████████████████████| 6/6 [00:00<00:00, 51781.53it/s]\n",
      "Start hashing 7 files.\n",
      "Finished hashing 7 files.\n",
      "/Users/juanbeiroa/Library/Caches/pypoetry/virtualenvs/thereisnohr-HzDUGj03-py3.12/lib/python3.12/site-packages/huggingface_hub/utils/_experimental.py:58: UserWarning: 'plan_multi_commits' is experimental and might be subject to breaking changes in the future. You can disable this warning by setting `HF_HUB_DISABLE_EXPERIMENTAL_WARNING=1` as environment variable.\n",
      "  warnings.warn(\n",
      "/Users/juanbeiroa/Library/Caches/pypoetry/virtualenvs/thereisnohr-HzDUGj03-py3.12/lib/python3.12/site-packages/huggingface_hub/utils/_experimental.py:58: UserWarning: 'HfApi.create_commits_on_pr' is experimental and might be subject to breaking changes in the future. You can disable this warning by setting `HF_HUB_DISABLE_EXPERIMENTAL_WARNING=1` as environment variable.\n",
      "  warnings.warn(\n",
      "/Users/juanbeiroa/Library/Caches/pypoetry/virtualenvs/thereisnohr-HzDUGj03-py3.12/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'create_commits_on_pr' (from 'huggingface_hub.hf_api') is deprecated and will be removed from version '0.27'. This is an experimental feature. Please use `upload_large_folder` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Will create 0 deletion commit(s) and 2 addition commit(s), totalling 7 atomic operations.\n",
      "Multi-commits strategy with ID 68092766990319b4d99715c3fc5d7b22188f35f81ebcaef410335bc81fd41eba.\n",
      "New PR created: https://huggingface.co/jbeiroa/mlx_lora_llama-3.2-1b-q8/discussions/3\n",
      "model.safetensors: 100%|███████████████████| 2.47G/2.47G [02:00<00:00, 20.4MB/s]\n",
      "  step 8162c5aa4e4b9a49239da7cd58c876b82f8c9990ffefcce771e2a7c76fda5d45 completed (still 1 to go).\n",
      "Removing 6 file(s) from commit that have not changed.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "  step fac734db0522b3e1b18833920e05823a8cebe68b7f85e34576d4261754b13385 completed (still 0 to go).\n",
      "All commits have been pushed.\n",
      "PR is now open for reviews.\n",
      "PR has been automatically merged (`merge_pr=True` was passed).\n",
      "Upload successful, go to https://huggingface.co/jbeiroa/mlx_lora_llama-3.2-1b-q8 for details.\n"
     ]
    }
   ],
   "source": [
    "!mlx_lm.fuse --model jbeiroa/mlx_llama-3.2-1b-q8 --upload-repo jbeiroa/mlx_lora_llama-3.2-1b-q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560e85e-4a9c-449e-91c9-72de368732fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
