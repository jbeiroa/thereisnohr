{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4290a6c5-f2ad-40de-8204-5ecf36863a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf5277d-391b-4462-8354-35b29d6b7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/dataturks/resume-entities-for-ner?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 323k/323k [00:00<00:00, 600kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /Users/juanbeiroa/.cache/kagglehub/datasets/dataturks/resume-entities-for-ner/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# resume dataset from kaggle\n",
    "path = kagglehub.dataset_download(\"dataturks/resume-entities-for-ner\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50d4da15-1f19-4b93-afd1-280937e7fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions by K Scott Mader in https://www.kaggle.com/code/kmader/finding-good-parts-of-resumes/notebook\n",
    "base_json = path + '/Entity Recognition in Resumes.json'\n",
    "def pop_annot(raw_line):\n",
    "    in_line = defaultdict(list, **raw_line)\n",
    "    if 'annotation' in in_line:\n",
    "        labels = in_line['annotation']\n",
    "        for c_lab in labels:\n",
    "            if len(c_lab['label'])>0:\n",
    "                in_line[c_lab['label'][0]] += c_lab['points']\n",
    "    return in_line\n",
    "with open(base_json, 'r') as f:\n",
    "    # data is jsonl and so we parse it line-by-line\n",
    "    resume_data = [json.loads(f_line) for f_line in f.readlines()]\n",
    "    resume_df = pd.DataFrame([pop_annot(line) for line in resume_data])\n",
    "resume_df['length'] = resume_df['content'].map(len)\n",
    "\n",
    "def extract_higlights(raw_line):\n",
    "    in_line = defaultdict(list, **raw_line)\n",
    "    if 'annotation' in in_line:\n",
    "        labels = in_line['annotation']\n",
    "        for c_lab in labels:\n",
    "            if len(c_lab['label'])>0:\n",
    "                in_line['highlight'] += [dict(category = c_lab['label'][0], **cpts) for cpts in c_lab['points']]\n",
    "    return in_line\n",
    "resume_hl_df = pd.DataFrame([extract_higlights(line) for line in resume_data])\n",
    "resume_hl_df['length'] = resume_hl_df['content'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "012f0210-576d-4710-9db3-3b81f29de1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Skills': 'Teradata\\nMainframe\\nTeradata\\nMainframe\\nTeradata\\nJcl\\ncobol\\nMainframe\\nservicenow',\n",
       " 'College Name': 'Anurag College of Engineering (Jntuh)',\n",
       " 'Degree': 'Electrical and Electronics Engineering',\n",
       " 'Location': 'Hyderabad\\nHyderabad\\nHyderabad',\n",
       " 'Companies worked at': 'Infosys Limited\\nInfosys Limited',\n",
       " 'Designation': 'Senior Systems Engineer\\nSenior Systems Engineer',\n",
       " 'Email Address': 'indeed.com/r/Akhil-Yadav-Polemaina/\\nf6931801c51c63b1',\n",
       " 'Name': 'Akhil Yadav Polemaina'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_repeating_categories(data):\n",
    "    \"\"\"\n",
    "    Courtesy of ChatGPT.\n",
    "    Merges the text of repeating categories in a list of dictionaries.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list): A list of dictionaries with 'category' and 'text' keys.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are unique categories and values are merged texts.\n",
    "    \"\"\"\n",
    "    merged_categories = defaultdict(str)  # Initialize a defaultdict for concatenated text\n",
    "    \n",
    "    for entry in data:\n",
    "        category = entry['category']\n",
    "        text = entry['text']\n",
    "        # Append text with a separator (e.g., a space or newline)\n",
    "        merged_categories[category] += text.strip() + '\\n'\n",
    "    \n",
    "    # Remove trailing newlines in the final dictionary\n",
    "    return {category: text.strip() for category, text in merged_categories.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fafc221-7e29-4739-9cd4-2574a7192ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra cleaning of hihlights\n",
    "resume_hl_df['highlight'] = resume_hl_df['highlight'].map(merge_repeating_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9712481-1e86-4f3f-8762-8eb905eca4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_resume(data):\n",
    "    sections = ['Name', 'Skills', 'College Name', 'Degree', 'Companies worked at', 'Designation']\n",
    "    keys = [section for section in sections if section in data.keys()]\n",
    "    summary = \"\"\n",
    "    for key in keys:\n",
    "        summary += f\"*{key}*: {data[key]}.\\n\"\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33396bb2-5b66-47d7-a648-173a9fd7e1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*Name*: Afreen Jamadar.\\n*Skills*: Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql..\\n*College Name*: Shivaji University Kolhapur\\nCDAC ACTS.\\n*Degree*: Bachelor of Engg in Information Technology\\nPG-DAC.\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_resume(resume_hl_df['highlight'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3390b79-7050-4f4d-83ba-76b896747240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summarize_resume(resume_hl_df['highlight'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "308e0295-5681-4414-969f-2165bacd223f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1240"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resume_hl_df['content'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ddd6d6f6-ae2a-4038-a714-3f95e676056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_hl_df['summary'] = resume_hl_df['highlight'].map(summarize_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2cb82b5-0ce2-4334-b586-4998048ac50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_hl_df.drop('extras', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47f621ca-9ebd-48a9-9109-5b80673e27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fe0cd4d8-c4c8-46d0-aeb6-4e2bf8256af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(resume_hl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65727b10-5d26-487e-85b5-b358e3671b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.train_test_split(test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "da3087f5-c7e2-46ce-ade3-5519f4e259ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'annotation', 'highlight', 'length', 'summary'],\n",
       "        num_rows: 187\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['content', 'annotation', 'highlight', 'length', 'summary'],\n",
       "        num_rows: 33\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7fb66c08-fa10-4e91-8114-a2f0defbc890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f21cef66814b6c8b60fbf496d1541d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c66ffdd0dc43c39e6e21ca468d780e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f67834c55b40c097227b880f76255b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27af62fa85744d4abf21e8c963e06dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da18160991794b23844c992d5e605e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/33.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jbeiroa/resume_entities_ner_summaries/commit/856d2b9e2e73ec530d6146c557782845a4d912e4', commit_message='Upload dataset', commit_description='', oid='856d2b9e2e73ec530d6146c557782845a4d912e4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jbeiroa/resume_entities_ner_summaries', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jbeiroa/resume_entities_ner_summaries'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub('jbeiroa/resume_entities_ner_summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb7e19c-79b9-463c-a676-f4871993f413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
