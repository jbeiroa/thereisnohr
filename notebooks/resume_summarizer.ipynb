{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfdddc47-ebbb-4852-8ea7-7953d35d0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "import pymupdf\n",
    "import pymupdf4llm\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6f4f86b-fb08-47ca-9241-f9db63a3968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2040634e-cb51-4d11-b0a4-27e492baab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to demo files\n",
    "repo_path = os.path.dirname(os.getcwd())\n",
    "cvs_path = os.path.join(repo_path, 'cvs')\n",
    "cvs = [os.path.join(cvs_path, file) for file in os.listdir(cvs_path) if file.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bba20b9b-f02a-4909-9f74-afad91f23546",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Getter:\n",
    "    \"\"\"\n",
    "    A class for processing PDF files in a specified directory and converting them to markdown format.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    directory : str\n",
    "        Path to the directory containing PDF files.\n",
    "    save_to_file : bool, optional\n",
    "        If True, saves the converted markdown to a file. Defaults to False.\n",
    "    current_index : int\n",
    "        Tracks the index of the current file being processed. Initialized to 0.\n",
    "    files : List[str]\n",
    "        List of PDF files in the directory. Initialized during object creation.\n",
    "    markdown : Optional[str]\n",
    "        Holds the markdown representation of the last processed file. Defaults to None.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __post_init__():\n",
    "        Initializes the list of PDF files in the directory. Raises FileNotFoundError if no PDF files are found.\n",
    "    \n",
    "    get_cv(path: str) -> str:\n",
    "        Converts a PDF file at the specified path to markdown format.\n",
    "    \n",
    "    get_next() -> Optional[str]:\n",
    "        Processes the next PDF file in the directory and converts it to markdown format.\n",
    "        If `save_to_file` is True, saves the markdown to a file. Returns the markdown or None if no files remain.\n",
    "    \n",
    "    reset():\n",
    "        Resets the processing index to the beginning and clears the last processed markdown.\n",
    "    \"\"\"\n",
    "\n",
    "    directory: str\n",
    "    save_to_file: bool = False\n",
    "    current_index: int = field(init=False, default=0)\n",
    "    files: List[str] = field(init=False)\n",
    "    markdown: Optional[str] = field(init=False, default=None)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the list of PDF files in the directory. Raises a FileNotFoundError\n",
    "        if no PDF files are found in the specified directory.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FileNotFoundError\n",
    "            If no PDF files are found in the specified directory.\n",
    "        \"\"\"\n",
    "        self.files = [file for file in os.listdir(self.directory) if file.endswith('.pdf')]\n",
    "        if not self.files:\n",
    "            raise FileNotFoundError(\"No PDF files found in the specified directory.\")\n",
    "\n",
    "    def get_cv(self, path: str) -> str:\n",
    "        \"\"\"\n",
    "        Converts a PDF file at the specified path to markdown format.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Path to the PDF file to be converted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The markdown representation of the PDF file.\n",
    "        \"\"\"\n",
    "        self.markdown = pymupdf4llm.to_markdown(path, show_progress=False)\n",
    "        return self.markdown\n",
    "    \n",
    "    def get_next(self) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Processes the next PDF file in the directory and converts it to markdown format.\n",
    "        If `save_to_file` is True, saves the markdown to a file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Optional[str]\n",
    "            The markdown representation of the next PDF file, or None if no files remain.\n",
    "        \"\"\"\n",
    "        if self.current_index >= len(self.files):\n",
    "            return None\n",
    "        \n",
    "        current_file_path = os.path.join(self.directory, self.files[self.current_index])\n",
    "        self.current_index += 1\n",
    "        \n",
    "        self.markdown = self.get_cv(current_file_path)\n",
    "        \n",
    "        if self.save_to_file:\n",
    "            md_file_path = os.path.splitext(current_file_path)[0] + \".md\"\n",
    "            with open(md_file_path, 'w', encoding='utf-8') as md_file:\n",
    "                md_file.write(self.markdown)\n",
    "        \n",
    "        return self.markdown\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the processing index to the beginning and clears the last processed markdown.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.current_index = 0\n",
    "        self.markdown = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba13e24a-b2a8-46da-bc70-b5496dd3f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Handler():\n",
    "    resume: str\n",
    "\n",
    "    def split_by_blocks(self):\n",
    "        block_pattern = r'\\n\\n'\n",
    "        blocks = re.split(block_pattern, self.resume)\n",
    "        for idx, block in enumerate(blocks):\n",
    "            blocks[idx] = re.sub(r'#+\\s', '', block).lstrip('\\n')\n",
    "\n",
    "        blocks = list(filter(None, blocks))\n",
    "        return blocks\n",
    "    \n",
    "    def clean_resume_blocks(self):\n",
    "        \"\"\"\n",
    "        Cleans a list of text blocks by removing unwanted elements.\n",
    "        \n",
    "        Parameters:\n",
    "            blocks (list of str): The raw text blocks from a résumé.\n",
    "        \n",
    "        Returns:\n",
    "            list of str: The cleaned text blocks.\n",
    "        \"\"\"\n",
    "        extracted_links = []\n",
    "        unique_blocks = []\n",
    "        seen_blocks = set()\n",
    "        \n",
    "        for block in self.split_by_blocks():\n",
    "            # Remove special character sequences (e.g., '-----')\n",
    "            if re.match(r'^[\\-\\s]+$', block):\n",
    "                continue\n",
    "            \n",
    "            # Remove year ranges (e.g., '2022 - 2024', '2016 - Present')\n",
    "            if re.search(r'\\b\\d{4}\\s*-\\s*(\\d{4}|Present)\\b', block):\n",
    "                continue\n",
    "            \n",
    "            # Remove geographical data (e.g., 'Bs. As. Argentina')\n",
    "            if re.search(r'\\b(?:[A-Z][a-z]+\\.)+\\s*[A-Z][a-z]+(?:\\s*\\b[A-Z][a-z]+)?', block):\n",
    "                continue\n",
    "            \n",
    "            # Optionally, remove very short blocks (e.g., single words or short sequences)\n",
    "            if len(block.split()) < 3:\n",
    "                continue\n",
    "\n",
    "            # Find all links in the current block\n",
    "            links = re.findall(r'https?://[^\\s\\)\\]]+', block)\n",
    "            extracted_links.extend(links)\n",
    "    \n",
    "            # Remove links from the block\n",
    "            cleaned_block = re.sub(r'https?://[^\\s\\)\\]]+', '', block).strip()\n",
    "\n",
    "            # Remove leftover patterns like '[Some text] ()'\n",
    "            cleaned_block = re.sub(r'\\[([^\\[\\]]+)\\]\\s*\\(\\s*\\)', r'\\1', cleaned_block).strip()\n",
    "\n",
    "            # Normalize by removing newline characters and trimming extra spaces\n",
    "            normalized_block = ' '.join(cleaned_block.splitlines()).strip()\n",
    "    \n",
    "            # Check if the normalized version is already processed\n",
    "            if normalized_block not in seen_blocks:\n",
    "                seen_blocks.add(normalized_block)\n",
    "                unique_blocks.append(normalized_block)  # Keep the original formatting in the output\n",
    "            \n",
    "            text = \"\\n\".join(unique_blocks)\n",
    "            \n",
    "        return text, extracted_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3bf6f373-8301-4311-a329-de18c7ed134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Profiler:\n",
    "    \"\"\"\n",
    "    A class for summarizing résumés into structured categories using AI models.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    resume : str\n",
    "        The raw text of the résumé to summarize.\n",
    "    save_to_file : bool, optional\n",
    "        If True, saves the summary to a file. Defaults to False.\n",
    "    model : str, optional\n",
    "        The AI model used for generating the summary. Defaults to 'llama3.2:1b'.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    summarize() -> str:\n",
    "        Summarizes the résumé into a structured format based on predefined categories.\n",
    "    \"\"\"\n",
    "\n",
    "    resume: str\n",
    "    save_to_file: bool = False\n",
    "    model: str = 'llama3.2:1b'\n",
    "    categories: List[str] = field(default_factory=lambda: ['contact', 'education', 'experience', 'skills'])\n",
    "        \n",
    "    def summarize(self) -> str:\n",
    "        \"\"\"\n",
    "        Summarizes the résumé into a structured format based on predefined categories.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            A structured summary of the résumé including name, skills, experience, and education.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"You are a human resources expert, specialized in talent acquisition for schools.\n",
    "        You are tasked with summarizing résumés in the following structured format:\n",
    "        - Name: [Name here]\n",
    "        - Skills: [Skills listed here]\n",
    "        - Experience: [Job experience and other relevant experience here]\n",
    "        - Education: [Degrees obtained and courses taken]\n",
    "        \n",
    "        The summary should extract and organize the following details:\n",
    "        - Name: The candidate’s full name.\n",
    "        - Skills: List of technical and non-technical skills.\n",
    "        - Experience: Teaching/research positions, non-teaching roles, and any other relevant professional experience.\n",
    "        - Education: Degrees obtained and other studies, including courses taken.\n",
    "        \n",
    "        The following text is a candidate’s résumé:\n",
    "        \n",
    "        {self.resume}\n",
    "        \n",
    "        Provide the structured summary based on the given résumé. Do not output any explanatory text.\n",
    "        \"\"\"\n",
    "        response = ollama.generate(\n",
    "            model=self.model,\n",
    "            prompt=prompt\n",
    "        )\n",
    "        return response['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "94a60d9f-3312-471d-ba2b-9e6c31104f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juan Ignacio Beiroa\n",
      "- Skills: Git, Excel, Python, Javascript, HTML, CSS, Data Analytics & Machine Learning, SQL, Data Visualization, Physics, AI, Research & Problem-Solving, Secondary school Professor, Coordinator Languages\n",
      "- Experience:\n",
      "    - Teaching/Research Positions:\n",
      "        • Data Scientist (consulting)\n",
      "        • Researcher, Desercion-escolar-argentina.onrender.com\n",
      "    - Non-Teaching Roles:\n",
      "        • Advisor to the Secretary General, Federal Council of Education\n",
      "    - Other Relevant Professional Experience: \n",
      "        • Coordinator of Science and Technology Department, Bayard School\n",
      "    - Education:\n",
      "        • Data professional with a background in physics, education, and government advisory\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "\n",
      "**Reposición a las Instalaciones y Herramientas en la Facultad de Física, UBA**\n",
      "\n",
      "- Diseñar y implementar unidades didácticas específicas para ciertos cursos del programa de Física, como:\n",
      "  + Unidad Didáctica \"Beiroa J. I., Ruiz N. y Zarza L.\" (Primaria en Ciencias Naturales y Matemática)\n",
      "  + Unidad Didáctica \"Beiroa J. y Dionofrio J.\" (Informática Educativa)\n",
      "  \n",
      "**Organización de la Reunión Nacional de Enseñanza**\n",
      "\n",
      "- Desarrollar didacTIC.ar, un proyecto emprendido por docentes y ex estudiantes de la materia Informática Educativa, con el objetivo de ofrecer recursos digitales gratuitos a los docentes.\n",
      "- Realizar talleres y cursos para docentes sobre tecnología educativa.\n",
      "\n",
      "**Desarrollo Contenidos y Cursos en Informática Educativa**\n",
      "\n",
      "- Diseñar y dictar cursos y talleres sobre tecnología educativa, como:\n",
      "  + Curso de primeros auxilios y RCP DEA\n",
      "  + Comisión de Carrera de los Profesorados de Enseñanza Media y Superior\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "\n",
      "Name: Jibeiroa\n",
      "Skills:\n",
      "- Programming languages: SQL, Go, C++, etc.\n",
      "- Operating Systems: Linux, Windows\n",
      "- Data Analysis and Visualization Tools: Tableau, Power BI, Excel\n",
      "- Scientific Computing: MATLAB, Python, etc.\n",
      "- Data Science and Machine Learning\n",
      "- Business Intelligence and Analytics\n",
      "Experience:\n",
      "- Teaching/Education:\n",
      "  - Ayudante de 1ª de la materia Física e Introducción a la Biofísica de UBA XXI (Ministerio de Educación de la Nación)\n",
      "  - Asesor de la Secretaría General del Consejo Federal de Educación\n",
      "  - Asistente pedagógico y docente en la Escuela Técnica ORT\n",
      "- Research and Academia:\n",
      "  - Ministro de Educación de la Nación (June 2022 - January 2024)\n",
      "  - Ayudante de segunda del Departamento de Física\n",
      "- Other Professional Experience:\n",
      "  - Facultad de Ciencias Exactas y Naturales, UBA\n",
      "    - Ayudante de segunda\n",
      "  - Grupo de investigación orientado al estudio de propiedades termomecánicas en CuAlNi\n",
      "  - BGH S.A. Control de calidad\n",
      "Education:\n",
      "- Bachillerato Popular de Jóvenes y Adultos (IMPA)\n",
      "- Universidad Pedagógica Nacional (UNIPE)\n",
      "    - Especialista, Política Educativa\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "\n",
      "Name: Juan Ignacio Beiroa\n",
      "Skills: \n",
      "- Data Analytics\n",
      "- Machine Learning\n",
      "- Python\n",
      "- SQL\n",
      "- Git\n",
      "- Documentación\n",
      "- Comunicación\n",
      "- Excel\n",
      "- Javascript\n",
      "- HTML\n",
      "- CSS\n",
      "- Arduino\n",
      "- Liderazgo\n",
      "- Gestión de proyectos\n",
      "\n",
      "Experience:\n",
      "  + 2020 - Presente\n",
      "    Diplomatura en IA \n",
      "    Instructor y Asesor gubernamental en transición a la ciencia de datos\n",
      "  + Apr. 2024 - Presente\n",
      "    Física - Universidad de Buenos Aires\n",
      "  + Ago. 2023 - Dic. 2023\n",
      "    + 5000 estudiantes \n",
      "  + 2016 - Presente\n",
      "    Física para Biólogos, Geólogos y Químicos del\n",
      "    Coordinador del Departamento de Ciencia y Tecnología\n",
      "\n",
      "Education:\n",
      "  + Diplomatura en IA \n",
      "  + Universidad de Buenos Aires\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "\n",
      "No more files to process.\n"
     ]
    }
   ],
   "source": [
    "getter = Getter(directory=cvs_path)\n",
    "cv_summaries = []\n",
    "\n",
    "while True:\n",
    "    cv = getter.get_next()\n",
    "    if cv is None:\n",
    "        break\n",
    "    handler = Handler(cv)\n",
    "    data = handler.clean_resume_blocks()\n",
    "    profiler = Profiler(data[0])\n",
    "    summary = profiler.summarize()\n",
    "    cv_summaries.append(summary)\n",
    "    print(summary)\n",
    "    print('\\n\\n-------------------\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
